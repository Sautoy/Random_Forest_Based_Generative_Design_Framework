{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from joblib import load\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "np.set_printoptions(threshold=sys.maxsize, edgeitems=30, linewidth=100000, precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "def sample_grouped_train_data(train_input, train_output, train_fraction, group_size, random_state=42):\n",
    "\n",
    "    n_total_groups = len(train_input) // group_size\n",
    "    n_sample_groups = int(train_fraction * n_total_groups)\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    selected_group_indices = np.random.choice(n_total_groups, size=n_sample_groups, replace=False)\n",
    "\n",
    "    selected_row_indices = []\n",
    "    for group_idx in selected_group_indices:\n",
    "        start_idx = group_idx * group_size\n",
    "        selected_row_indices.extend(range(start_idx, start_idx + group_size))\n",
    "\n",
    "    train_input_sampled = train_input[selected_row_indices]\n",
    "    train_output_sampled = train_output[selected_row_indices]\n",
    "\n",
    "    return train_input_sampled, train_output_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "config_file_path = os.path.join(current_dir, 'config_regression.json')\n",
    "\n",
    "with open(config_file_path, 'r', encoding='utf-8') as file:\n",
    "    config = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# designs for training: 61860\n",
      "# designs for testing: 6930\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data\n",
    "training_data = pd.read_csv(config['training_data_path'], sep=',')\n",
    "testing_data = pd.read_csv(config['testing_data_path'], sep=',')\n",
    "\n",
    "# Prepare feature names\n",
    "des_var_names = config['design_variable_names']\n",
    "inp_var_names = des_var_names + ['strain']\n",
    "feature_names = inp_var_names\n",
    "n_inp = len(inp_var_names)\n",
    "\n",
    "x_train = training_data[inp_var_names].to_numpy().reshape(-1, n_inp)\n",
    "y_train = training_data['stress'].to_numpy().flatten()\n",
    "\n",
    "# Prepare input/output for training\n",
    "# x_train = training_data[inp_var_names].to_numpy().reshape(-1, n_inp)\n",
    "# y_train = training_data['stress'].to_numpy().flatten()\n",
    "\n",
    "# Prepare input/output for testing\n",
    "x_test = testing_data[inp_var_names].to_numpy().reshape(-1, n_inp)\n",
    "y_test = testing_data['stress'].to_numpy().flatten()\n",
    "\n",
    "# Output dataset size\n",
    "print('# designs for training:', x_train.shape[0])\n",
    "print('# designs for testing:', x_test.shape[0])\n",
    "\n",
    "# Create result folder\n",
    "folder_name = 'results_rf_regression'\n",
    "create_dir(folder_name)\n",
    "\n",
    "# Save design variable bounds from training set\n",
    "des_var_bounds = np.vstack([np.min(x_train[:,:-1], axis=0), np.max(x_train[:,:-1], axis=0)]).T\n",
    "np.save(f'{folder_name}/des_var_bounds.npy', des_var_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=10, Train MAPE=0.0867, Test MAPE=0.0978, Train MSE=0.0003, Test MSE=0.0004\n",
      "max_depth=12, Train MAPE=0.0513, Test MAPE=0.0654, Train MSE=0.0001, Test MSE=0.0002\n",
      "max_depth=15, Train MAPE=0.0208, Test MAPE=0.0403, Train MSE=0.0000, Test MSE=0.0001\n",
      "max_depth=20, Train MAPE=0.0104, Test MAPE=0.0350, Train MSE=0.0000, Test MSE=0.0001\n",
      "max_depth=25, Train MAPE=0.0101, Test MAPE=0.0349, Train MSE=0.0000, Test MSE=0.0001\n",
      "max_depth=50, Train MAPE=0.0101, Test MAPE=0.0349, Train MSE=0.0000, Test MSE=0.0001\n",
      "max_depth=100, Train MAPE=0.0101, Test MAPE=0.0349, Train MSE=0.0000, Test MSE=0.0001\n",
      "Tree depth tuning result saved to rf_depth.csv\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "depths = [10, 12, 15, 20, 25, 50]\n",
    "train_mape_list = []\n",
    "test_mape_list = []\n",
    "train_mse_list = []\n",
    "test_mse_list = []\n",
    "\n",
    "for d in depths:\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=config['num_estimators'],\n",
    "        criterion='squared_error',\n",
    "        max_depth=d,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=0\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "\n",
    "    # MAPE\n",
    "    mape_train = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "    mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "\n",
    "    # MSE\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "    train_mape_list.append(mape_train)\n",
    "    test_mape_list.append(mape_test)\n",
    "    train_mse_list.append(mse_train)\n",
    "    test_mse_list.append(mse_test)\n",
    "\n",
    "    print(f\"max_depth={d}, \"\n",
    "          f\"Train MAPE={mape_train:.4f}, Test MAPE={mape_test:.4f}, \"\n",
    "          f\"Train MSE={mse_train:.4f}, Test MSE={mse_test:.4f}\")\n",
    "\n",
    "    # dump(model, f'{folder_name}/forest_depth_{d}.joblib')\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"max_depth\": depths,\n",
    "    \"train_mape\": train_mape_list,\n",
    "    \"test_mape\": test_mape_list,\n",
    "    \"train_mse\": train_mse_list,\n",
    "    \"test_mse\": test_mse_list\n",
    "})\n",
    "results_df.to_csv(\"rf_depth.csv\", index=False)\n",
    "print(\"Tree depth tuning result saved to rf_depth.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data efficiency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight='balanced'\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record results\n",
    "data_efficiency_results = []\n",
    "\n",
    "# Sweep over different training fractions\n",
    "for train_fraction in np.linspace(0.1, 1, 10):\n",
    "    # training_data_sampled = training_data.sample(frac=train_fraction, random_state=42)\n",
    "    # x_train = training_data_sampled[inp_var_names].to_numpy().reshape(-1, n_inp)\n",
    "    # y_train = training_data_sampled['stress'].to_numpy().flatten()\n",
    "\n",
    "    x_train_sampled, y_train_sampled = sample_grouped_train_data(x_train, y_train, train_fraction, group_size=30, random_state=42)\n",
    "\n",
    "    # Save bounds for the current training set (optional)\n",
    "    des_var_bounds = np.vstack([np.min(x_train_sampled[:, :-1], axis=0), np.max(x_train_sampled[:, :-1], axis=0)]).T\n",
    "    np.save(f'{folder_name}/des_var_bounds_{int(train_fraction*100)}.npy', des_var_bounds)\n",
    "\n",
    "    # Train model\n",
    "    reg = RandomForestRegressor(n_estimators=config['num_estimators'],\n",
    "                                 criterion='squared_error',\n",
    "                                 max_depth=15,\n",
    "                                 min_samples_split=2,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 random_state=42)\n",
    "    reg.fit(x_train_sampled, y_train_sampled)\n",
    "\n",
    "    # Evaluate on train\n",
    "    y_pred_train_sampled = reg.predict(x_train_sampled)\n",
    "    mse_train = mean_squared_error(y_train_sampled, y_pred_train_sampled)\n",
    "    mae_train = mean_absolute_error(y_train_sampled, y_pred_train_sampled)\n",
    "    mape_train = mean_absolute_percentage_error(y_train_sampled, y_pred_train_sampled)\n",
    "    # Evaluate on test\n",
    "    y_pred_test = reg.predict(x_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "\n",
    "    # Store results\n",
    "    data_efficiency_results.append({\n",
    "        'fraction': train_fraction,\n",
    "        'mse_train': mse_train,\n",
    "        'mae_train': mae_train,\n",
    "        'mape_train': mape_train,\n",
    "        'mse_test': mse_test,\n",
    "        'mae_test': mae_test,\n",
    "        'mape_test': mape_test,\n",
    "        'n_train': len(x_train_sampled)\n",
    "    })\n",
    "\n",
    "    dump(reg, f'{folder_name}/forest_{int(train_fraction*100)}.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = pd.DataFrame(data_efficiency_results)\n",
    "results_df.to_csv(\"results_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 3.01s\n",
      "Training MSE: 1.490745000340074e-05\n",
      "Training MAE: 0.0028037886643695223\n",
      "Training MAPE: 0.018725340318051478\n",
      "Training R2: 0.9994182203265911\n",
      "Test MSE: 0.00015600136674686878\n",
      "Test MAE: 0.008629479701011359\n",
      "Test MAPE: 0.05699459797577057\n",
      "Test R2: 0.9931315309820675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['results_rf_regression/forest.joblib']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Train a random forest\n",
    "start_time = time.time()\n",
    "reg = RandomForestRegressor(n_estimators=config['num_estimators'], criterion='squared_error',\n",
    "                            max_depth=15, min_samples_split=2, min_samples_leaf=1, random_state=42)\n",
    "\n",
    "final_fraction = 0.4\n",
    "x_train_sampled, y_train_sampled = sample_grouped_train_data(x_train, y_train, final_fraction, group_size=30, random_state=42)\n",
    "reg = reg.fit(x_train_sampled, y_train_sampled)\n",
    "print('Training time: {:.2f}s'.format(time.time()-start_time))\n",
    "\n",
    "# Evaluate the model on training data\n",
    "y_pred_train = reg.predict(x_train_sampled)\n",
    "mse_train = mean_squared_error(y_train_sampled, y_pred_train)\n",
    "mae_train = mean_absolute_error(y_train_sampled, y_pred_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train_sampled, y_pred_train)\n",
    "r2_train = r2_score(y_train_sampled, y_pred_train)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred_test = reg.predict(x_test)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "# Print results\n",
    "print('Training MSE:', mse_train)\n",
    "print('Training MAE:', mae_train)\n",
    "print('Training MAPE:', mape_train)\n",
    "print('Training R2:', r2_train)\n",
    "\n",
    "print('Test MSE:', mse_test)\n",
    "print('Test MAE:', mae_test)\n",
    "print('Test MAPE:', mape_test)\n",
    "print('Test R2:', r2_test)\n",
    "\n",
    "# Save results to file\n",
    "lines = [\n",
    "    'Train MSE: {:.4f}'.format(mse_train),\n",
    "    'Train MAE: {:.4f}'.format(mae_train),\n",
    "    'Train MAPE: {:.4f}'.format(mape_train),\n",
    "    'Train R2: {:.4f}'.format(r2_train),\n",
    "    'Test MSE: {:.4f}'.format(mse_test),\n",
    "    'Test MAE: {:.4f}'.format(mae_test),\n",
    "    'Test MAPE: {:.4f}'.format(mape_test),\n",
    "    'Test R2: {:.4f}'.format(r2_test)\n",
    "]\n",
    "\n",
    "with open(f'{folder_name}/forest_regression_acc.txt', 'w') as f:\n",
    "    f.write('\\n'.join(lines))\n",
    "\n",
    "# Save the model\n",
    "dump(reg, f'{folder_name}/forest.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_train_data = np.hstack([x_train_sampled, y_train_sampled.reshape(-1, 1)])\n",
    "col_names = inp_var_names + [\"stress\"]\n",
    "used_train_df = pd.DataFrame(used_train_data, columns=col_names)\n",
    "used_train_df.to_csv(f\"stress_strain_training_data_fraction_{int(final_fraction*100)}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ recovered: (824, 36)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "used_dataset = pd.read_csv(f\"stress_strain_training_data_fraction_{int(final_fraction*100)}.csv\")\n",
    "used_dataset[\"strain_idx\"] = used_dataset.groupby(['L', 'w', 'alpha', 'num_vert', 'num_hori']).cumcount()\n",
    "\n",
    "used_dataset_flatten = used_dataset.pivot(\n",
    "    index=['L', 'w', 'alpha', 'num_vert', 'num_hori'],\n",
    "    columns='strain_idx',\n",
    "    values='stress'\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "n_stress = used_dataset_flatten.shape[1] - 5  \n",
    "\n",
    "stress_cols = [f\"s{i}\" for i in range(2, n_stress + 2)]\n",
    "used_dataset_flatten.columns = ['L', 'w', 'alpha', 'num_vert', 'num_hori'] + stress_cols\n",
    "\n",
    "used_dataset_flatten.insert(5, \"s1\", 0)\n",
    "\n",
    "param_cols = ['L', 'w', 'alpha', 'num_vert', 'num_hori']\n",
    "stress_cols = [f\"s{i}\" for i in range(1, n_stress + 2)]\n",
    "used_dataset_flatten = used_dataset_flatten[param_cols + stress_cols]\n",
    "\n",
    "used_dataset_flatten.to_excel(f'train_fraction_{int(final_fraction*100)}.xlsx', index=False)\n",
    "\n",
    "print(\"✅ recovered:\", used_dataset_flatten.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot decision tree\n",
    "\n",
    "Take a lot of time when tree is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import export_graphviz\n",
    "# import graphviz\n",
    "# from IPython.display import display\n",
    "\n",
    "# tree = reg.estimators_[2]\n",
    "\n",
    "# dot_data = export_graphviz(tree, out_file=None, \n",
    "#                            feature_names=inp_var_names,        \n",
    "#                            filled=True, rounded=True, \n",
    "#                            special_characters=True)  \n",
    "\n",
    "# graph = graphviz.Source(dot_data)  \n",
    "\n",
    "# graph.render(\"decision_tree\", format=\"pdf\", cleanup=True)  \n",
    "\n",
    "# display(graph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rigid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
